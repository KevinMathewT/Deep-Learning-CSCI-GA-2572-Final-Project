{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder2D(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(2, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 16, 16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Encoder2D(nn.Module):\n",
    "    def __init__(self, repr_dim, input_size=65):\n",
    "        super().__init__()\n",
    "        self.repr_dim = repr_dim\n",
    "        self.output_side = int(math.sqrt(repr_dim))  # Calculate the side of the 2D embedding\n",
    "\n",
    "        # Determine the number of convolutional blocks required\n",
    "        self.num_conv_blocks = int(math.log2(input_size / self.output_side))\n",
    "        if 2 ** self.num_conv_blocks * self.output_side != 2 ** int(math.log2(input_size)):\n",
    "            raise ValueError(\"Cannot evenly reduce input_size to output_side using stride-2 convolutions.\")\n",
    "\n",
    "        layers = []\n",
    "        in_channels = 2  # Input has 2 channels (agent and wall)\n",
    "        out_channels = 32  # Start with 32 output channels\n",
    "        for i in range(self.num_conv_blocks):\n",
    "            layers.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=3,\n",
    "                    stride=2,\n",
    "                    padding=0,\n",
    "                ) if i == 0 else\n",
    "                nn.Conv2d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=3,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                )\n",
    "            )  # Halve the spatial dimensions\n",
    "            layers.append(nn.ReLU())\n",
    "            in_channels = out_channels\n",
    "            out_channels = min(out_channels * 2, 256)  # Cap channels at 256\n",
    "\n",
    "        # Final convolution to reduce to single-channel output\n",
    "        layers.append(nn.Conv2d(in_channels, 1, kernel_size=1))  # Single-channel embedding\n",
    "\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input: (B, 2, 65, 65)\n",
    "        x = self.conv(x)  # Dynamically reduce to (B, 1, output_side, output_side)\n",
    "        return x  # Output shape: (B, 1, output_side, output_side)\n",
    "\n",
    "# Instantiate the Encoder2D with input size 65x65 and repr_dim 256\n",
    "encoder = Encoder2D(repr_dim=256, input_size=65)\n",
    "print(encoder)\n",
    "\n",
    "# Test with a dummy input\n",
    "input_tensor = torch.randn(1, 2, 65, 65)  # Batch size of 1, 2 channels, 65x65 input\n",
    "output = encoder(input_tensor)\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
